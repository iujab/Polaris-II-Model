{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "65a67972",
            "metadata": {},
            "source": [
                "<div class=\"output_png output_subarea output_execute_result\">\n",
                "<img src=https://nsiripun.github.io/Polaris-II-Model/polariscometlogo.png width=\"800px\"/>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d41e6a7",
            "metadata": {},
            "source": [
                "Real-Time weather downloader based on ECMWF weather forecast for the Polaris WEBSITE. Model downloader separate. Features 3-hourly weather forecasts for 10 days with minimum 0.4° spatial resolution (~44 km). Forecast is in real-time updated every 6 hours through ECMWF dissemination scheme. "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ae8ec204",
            "metadata": {},
            "source": [
                "## Create Downloader Grid ##"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "dba3d902",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading Terrain: 100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 567.95it/s]\n"
                    ]
                }
            ],
            "source": [
                "import math\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "import time\n",
                "import folium\n",
                "import numpy as np\n",
                "for i in tqdm(range(1),ncols = 100, desc = 'Loading Terrain'):\n",
                "    radius = 1000.0 # m - the following code is an approximation that stays reasonably accurate for distances < 100km\n",
                "    centerLat = 37.421160# latitude of circle center, decimal degrees\n",
                "    centerLon = 141.032389  # Longitude of circle center, decimal \n",
                "    # parameters\n",
                "    N = 10 # number of discrete sample points to be generated along the circle\n",
                "    scale = 100\n",
                "    # generate points\n",
                "    lat, lon = centerLat, centerLon #center coordinate\n",
                "    dist, coors = 200000, 15 #meters, num coordinates in each direction\n",
                "\n",
                "    #Creating the offset grid\n",
                "    mini, maxi = -dist*coors, dist*coors\n",
                "    n_coord = coors*2+1\n",
                "    axis = np.linspace(mini, maxi, n_coord)\n",
                "    X, Y = np.meshgrid(axis, axis)\n",
                "\n",
                "\n",
                "    #avation formulate for offsetting the latlong by offset matrices\n",
                "    R = 6378137 #earth's radius\n",
                "    dLat = X/R\n",
                "    dLon = Y/(R*np.cos(np.pi*lat/180))\n",
                "    latO = lat + dLat * 180/np.pi\n",
                "    lonO = lon + dLon * 180/np.pi\n",
                "\n",
                "    #stack x and y latlongs and get (lat,long) format\n",
                "    output = np.stack([latO, lonO]).transpose(1,2,0)\n",
                "\n",
                "    circlePoints = []\n",
                "    nodes = []\n",
                "    mapnodes = []\n",
                "    for i in output:\n",
                "        for x in i:\n",
                "            circlePoints.append({'lat':x[0],'lon':x[-1]})\n",
                "    for i in circlePoints:\n",
                "        u_lon = i['lon']\n",
                "        u_lat = i['lat']\n",
                "        nodes.append([u_lon,u_lat])\n",
                "        mapnodes.append([u_lat,u_lon])\n",
                "    #print(nodes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "9c870adb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Server Local Time Is: 2022-04-18T17:28\n",
                        "UTC Time Is: 2022-04-19T00:28\n",
                        "Connected to API\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Syncing Real-Time Data For UTC 2022-04-19T00:00 Timestep: 100%|███| 961/961 [11:07<00:00,  1.44it/s]\n"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "import math\n",
                "import requests\n",
                "from datetime import datetime\n",
                "from datetime import datetime,timezone\n",
                "import metpy\n",
                "from metpy.calc import wind_components\n",
                "from metpy.units import units\n",
                "\n",
                "print('Server Local Time Is:', datetime.now().strftime(\"%Y-%m-%dT%H:%M\"))\n",
                "print('UTC Time Is:', datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M\"))\n",
                "import math\n",
                "import json\n",
                "#Test API Server\n",
                "response = requests.get(\"https://api.open-meteo.com/v1/forecast?latitude=37.42&longitude=141.03&hourly=windspeed_10m,winddirection_10m\")\n",
                "if (response.status_code == 200):\n",
                "    print(\"Connected to API\", flush=True)\n",
                "    response = response.json()\n",
                "    # Code here will only run if the request is successful\n",
                "elif (response.status_code == 404):\n",
                "    print(\"API Server Error: 404\")\n",
                "    try:\n",
                "        response = requests.get('http://api.open-notify.org/astros.json', timeout=5)\n",
                "        response.raise_for_status()\n",
                "        # Code here will only run if the request is successful\n",
                "    except requests.exceptions.HTTPError as errh:\n",
                "        print(errh)\n",
                "    except requests.exceptions.ConnectionError as errc:\n",
                "        print(errc)\n",
                "    except requests.exceptions.Timeout as errt:\n",
                "        print(errt)\n",
                "    except requests.exceptions.RequestException as err:\n",
                "        print(err)\n",
                "\n",
                "#Download Data\n",
                "\n",
                "def getuv1(direction,speed):\n",
                "    v = -abs(speed) * math.cos(direction*(math.pi/180))\n",
                "    u = -abs(speed) * math.sin(direction*(math.pi/180))\n",
                "    return [u,v]\n",
                "def getuv(direction,speed):\n",
                "    metx = units.Quantity(speed, \"m/s\")\n",
                "    metpyout = metpy.calc.wind_components(metx, math.radians(direction))\n",
                "    return [metpyout[0].magnitude,metpyout[-1].magnitude]\n",
                "\n",
                "\n",
                "    \n",
                "timerun = response[\"hourly\"][\"time\"][:33] #get the first 3 days of forecast\n",
                "direction = response[\"hourly\"][\"winddirection_10m\"][:33] #conv to uv operation\n",
                "speed = response[\"hourly\"][\"windspeed_10m\"][:33]\n",
                "apidata = {}\n",
                "currentsynctime = list(response['hourly']['time'])[0]\n",
                "time.sleep(0.01)\n",
                "for i in timerun:\n",
                "    apidata[i] = []\n",
                "for p in tqdm(nodes, ncols = 100, desc = f'Syncing Real-Time Data For UTC {currentsynctime} Timestep'):\n",
                "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={p[-1]}&longitude={p[0]}&hourly=windspeed_80m,winddirection_80m\")\n",
                "    response = response.json()\n",
                "    timerun = response[\"hourly\"][\"time\"][:33] #get the first 3 days of forecast\n",
                "    direction = response[\"hourly\"][\"winddirection_80m\"][:33] #conv to uv operation\n",
                "    speed = response[\"hourly\"][\"windspeed_80m\"][:33]\n",
                "    for i in range(len(timerun)):\n",
                "        indexer = timerun[i]\n",
                "        uv = getuv(direction[i],speed[i])\n",
                "        #print(uv)\n",
                "        apidata[indexer].append({'u_component_of_wind_10m':uv[0],'v_component_of_wind_10m':uv[-1]})\n",
                "\n",
                "\n",
                "#print(apidata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "6b592bcf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Write Skips:  0\n"
                    ]
                }
            ],
            "source": [
                "#print(len(apidata[date]))\n",
                "textfile = open(\"fukutemp.txt\", \"w\")\n",
                "skipint = 0\n",
                "for date in timerun:\n",
                "    textfile.write(date + \"\\n\")\n",
                "    for i in range(len(apidata[date])):\n",
                "        try:\n",
                "            #print(apidata[date][i])\n",
                "            #txtwrite = (apidata[date][i].update(apidata[date][i+1]))\n",
                "            #print(txtwrite)\n",
                "            textfile.write(str(apidata[date][i]) +'\\n')\n",
                "        except:\n",
                "            skipint = skipint + 1\n",
                "        #textfile.write(str(i.update(apidata[date][apidata[date].index(i)+1])) + \"\\n\")\n",
                "        #print(str(i.update(apidata[date][apidata[date].index(i)+1])) + \"\\n\")\n",
                "textfile.close()\n",
                "print('Write Skips: ', skipint)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f46641e7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading Terrain: 100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 564.97it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Displaying Wind Data For 2022-04-19T00:42 UTC\n",
                        "updated node:  962\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f0a9b746794c4c69a75dc2c871d21e39",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map(center=[37.396113, 140.47733], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title',…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import ast\n",
                "import json\n",
                "import plotly.graph_objs as go\n",
                "from datetime import datetime,timezone,timedelta\n",
                "import math\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "import time\n",
                "import folium\n",
                "import numpy as np\n",
                "import IPython\n",
                "\n",
                "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel to flush iPyleaflet Variables\n",
                "\n",
                "\n",
                "now_utc = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M\")\n",
                "input_utc = datetime.now(timezone.utc)\n",
                "\n",
                "\n",
                "def hour_rounder(t):\n",
                "    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n",
                "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour)\n",
                "               +timedelta(hours=t.minute//30))\n",
                "\n",
                "\n",
                "search_utc = hour_rounder(input_utc)\n",
                "search_utc = search_utc.strftime(\"%Y-%m-%dT%H:00\")\n",
                "print('Displaying Wind Data For', now_utc, 'UTC')\n",
                "\n",
                "with open('fukutemp.txt') as f:\n",
                "    content = f.readlines()\n",
                "extracted = []\n",
                "\n",
                "index = [x for x in range(len(content)) if str(search_utc) in content[x]][-1]\n",
                "print(\"updated node: \", index)\n",
                "for i in range(index+1,index+962):\n",
                "    extracted.append(ast.literal_eval(content[i]))\n",
                "open('fukuCOMET.txt', 'w').close() \n",
                "#print(extracted)\n",
                "\n",
                "#Re-node GENERATION\n",
                "for i in tqdm(range(1),ncols = 100, desc = 'Loading Terrain'):\n",
                "    radius = 1000.0 # m - the following code is an approximation that stays reasonably accurate for distances < 100km\n",
                "    centerLat = 37.421160# latitude of circle center, decimal degrees\n",
                "    centerLon = 141.032389  # Longitude of circle center, decimal \n",
                "    # parameters\n",
                "    N = 10 # number of discrete sample points to be generated along the circle\n",
                "    scale = 100\n",
                "    # generate points\n",
                "    lat, lon = centerLat, centerLon #center coordinate\n",
                "    dist, coors = 200000, 15 #meters, num coordinates in each direction\n",
                "\n",
                "    #Creating the offset grid\n",
                "    mini, maxi = -dist*coors, dist*coors\n",
                "    n_coord = coors*2+1\n",
                "    axis = np.linspace(mini, maxi, n_coord)\n",
                "    X, Y = np.meshgrid(axis, axis)\n",
                "\n",
                "\n",
                "    #avation formulate for offsetting the latlong by offset matrices\n",
                "    R = 6378137 #earth's radius\n",
                "    dLat = X/R\n",
                "    dLon = Y/(R*np.cos(np.pi*lat/180))\n",
                "    latO = lat + dLat * 180/np.pi\n",
                "    lonO = lon + dLon * 180/np.pi\n",
                "\n",
                "    #stack x and y latlongs and get (lat,long) format\n",
                "    output = np.stack([latO, lonO]).transpose(1,2,0)\n",
                "\n",
                "    circlePoints = []\n",
                "    nodes = []\n",
                "    mapnodes = []\n",
                "    for i in output:\n",
                "        for x in i:\n",
                "            circlePoints.append({'lat':x[0],'lon':x[-1]})\n",
                "    for i in circlePoints:\n",
                "        u_lon = i['lon']\n",
                "        u_lat = i['lat']\n",
                "        nodes.append([u_lon,u_lat])\n",
                "        mapnodes.append([u_lat,u_lon])\n",
                "\n",
                "\n",
                "from ipyleaflet import Map, basemaps\n",
                "from ipyleaflet.velocity import Velocity\n",
                "geedata = {'lat':[],'lon':[],'u_wind':[],'v_wind':[]} \n",
                "\n",
                "\n",
                "for i in range(len(mapnodes)):\n",
                "    geedata['lat'].append(mapnodes[i][0])\n",
                "    geedata['lon'].append(mapnodes[i][-1])\n",
                "    geedata['u_wind'].append(extracted[i]['u_component_of_wind_10m'])\n",
                "    geedata['v_wind'].append(extracted[i]['v_component_of_wind_10m'])\n",
                "df = pd.DataFrame(geedata)\n",
                "df = df.set_index(['lat', 'lon'])\n",
                "geedataxr = df.to_xarray()\n",
                "\n",
                "\n",
                "map12_ = Map(\n",
                "    center=(37.396113, 140.477330),\n",
                "    zoom=7,\n",
                "    interpolation=\"linear\",\n",
                "    basemap=basemaps.CartoDB.DarkMatter,\n",
                ")\n",
                "\n",
                "wind_map = Velocity(\n",
                "    data=geedataxr,\n",
                "    zonal_speed=\"u_wind\",\n",
                "    meridional_speed=\"v_wind\",\n",
                "    latitude_dimension=\"lat\",\n",
                "    longitude_dimension=\"lon\",\n",
                "    velocity_scale=0.001,\n",
                "    max_velocity= 35,\n",
                ")\n",
                "\n",
                "map12_.add_layer(wind_map)\n",
                "map12_.save(\"fukuCOMET.txt\")\n",
                "map12_\n",
                "#clean text file\n",
                "\n",
                "\n",
                "#print(extracted)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6a8ea515",
            "metadata": {},
            "source": [
                "## Hosting JSON Files to Web Interface ##"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "e648c56b",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import linecache\n",
                "\n",
                "with open(r'fukuCOMET.txt', 'r') as fp:\n",
                "    # read line number 3 to 5\n",
                "    # index starts from 0\n",
                "    x = fp.readlines()[175:2137]\n",
                "x[0] =  '[\\n' #cleanup\n",
                "x[-1] = ']\\n'\n",
                "with open('fukuCOMETjson.json', 'w') as f:\n",
                "    for i in x:\n",
                "        f.write(i)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c6710d3f",
            "metadata": {},
            "source": [
                "*# HTTPRequest in JS #*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "a20c89a4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\"metaData\":{\"id\":\"625c241cbc312b30ebe8694a\",\"versionsDeleted\":1},\"message\":\"Versions for the Bin are deleted successfully and latest version preserved on the base record.\"}\n"
                    ]
                }
            ],
            "source": [
                "import requests\n",
                "import json\n",
                "url = 'https://api.jsonbin.io/b/625c241cbc312b30ebe8694a'\n",
                "headers = {\n",
                "  'Content-Type': 'application/json',\n",
                "  'X-Master-Key': '<$2b$10$XzVYIgLc388T1ZmF6jmG..DjmOsA5XjnbkvinDYG9BwdWn8NhFudK>'\n",
                "}\n",
                "f = open('fukuCOMETjson.json')\n",
                " \n",
                "# returns JSON object as\n",
                "# a dictionary\n",
                "data = json.load(f)\n",
                "\n",
                "req = requests.put(url, json=data, headers=headers)\n",
                "#print(req.text)\n",
                "url = 'https://api.jsonbin.io/v3/b/625c241cbc312b30ebe8694a/versions'\n",
                "\n",
                "headers2 = {\n",
                "  'X-Master-Key': '$2b$10$XzVYIgLc388T1ZmF6jmG..DjmOsA5XjnbkvinDYG9BwdWn8NhFudK',\n",
                "  'X-preserve-latest':'true'\n",
                "} #roll back versioning\n",
                "\n",
                "\n",
                "req = requests.delete(url, json=None, headers=headers2)\n",
                "print(req.text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c627ff74",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
